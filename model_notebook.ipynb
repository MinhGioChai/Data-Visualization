{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f74721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46771318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: 215258 rows, 122 columns\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('raw_data/train.csv')\n",
    "print(f'Shape: {df.shape[0]} rows, {df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb650ab",
   "metadata": {},
   "source": [
    "## **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96c091f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: 5961\n",
      "Class distribution after SMOTE:\n",
      "TARGET\n",
      "0    4481\n",
      "1    4481\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ”¢ Prediction Counts:\n",
      "0    1181\n",
      "1      12\n",
      "Name: count, dtype: int64\n",
      "ðŸ“Œ XGBoost Results\n",
      "----------------------------\n",
      "Train Accuracy : 0.9830\n",
      "Test Accuracy  : 0.9413\n",
      "Train ROC-AUC  : 0.9989\n",
      "Test ROC-AUC   : 0.6519\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1131\n",
      "           1       0.17      0.03      0.05        62\n",
      "\n",
      "    accuracy                           0.94      1193\n",
      "   macro avg       0.56      0.51      0.51      1193\n",
      "weighted avg       0.91      0.94      0.92      1193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "df = df.copy()\n",
    "df = df.dropna()\n",
    "print(f'shape: {df.shape[0]}')\n",
    "# Features and target variable\n",
    "X = df.drop('TARGET', axis=1)  # Features\n",
    "y = df['TARGET']  # Target variable\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category')\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Apply SMOTE to balance the training data\n",
    "cat_features = [i for i, col in enumerate(X_train.columns) if X_train[col].dtype.name == 'category']\n",
    "smote = SMOTENC(categorical_features=cat_features, random_state=42)\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after SMOTE\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(y_train_smote.value_counts())\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    enable_categorical=True,\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    tree_method='hist',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Predictions\n",
    "# ---------------------------\n",
    "# Train predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Test predictions\n",
    "y_test_pred = model.predict(X_test)\n",
    "# Convert to pandas Series to use value_counts()\n",
    "y_test_pred_series = pd.Series(y_test_pred)\n",
    "\n",
    "print(\"\\nðŸ”¢ Prediction Counts:\")\n",
    "print(y_test_pred_series.value_counts())\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Evaluation\n",
    "# ---------------------------\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc  = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "test_auc  = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"ðŸ“Œ XGBoost Results\")\n",
    "print(\"----------------------------\")\n",
    "print(f\"Train Accuracy : {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy  : {test_acc:.4f}\")\n",
    "print(f\"Train ROC-AUC  : {train_auc:.4f}\")\n",
    "print(f\"Test ROC-AUC   : {test_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f4b030",
   "metadata": {},
   "source": [
    "## **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f792e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¢ Prediction Counts:\n",
      "0    42930\n",
      "1      122\n",
      "Name: count, dtype: int64\n",
      "ðŸ“Œ XGBoost Results\n",
      "----------------------------\n",
      "Train Accuracy : 0.9213\n",
      "Test Accuracy  : 0.9194\n",
      "Train ROC-AUC  : 0.8228\n",
      "Test ROC-AUC   : 0.7552\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     39576\n",
      "           1       0.52      0.02      0.04      3476\n",
      "\n",
      "    accuracy                           0.92     43052\n",
      "   macro avg       0.72      0.51      0.50     43052\n",
      "weighted avg       0.89      0.92      0.88     43052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Prepare data\n",
    "# ---------------------------\n",
    "df= pd.read_csv('train.csv')\n",
    "df = df.copy()\n",
    "\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "# Convert all object columns to category\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category')\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. XGBoost Model\n",
    "# ---------------------------\n",
    "model = xgb.XGBClassifier(\n",
    "    enable_categorical=True,\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    tree_method='hist',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Predictions\n",
    "# ---------------------------\n",
    "# Train predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Test predictions\n",
    "y_test_pred = model.predict(X_test)\n",
    "# Convert to pandas Series to use value_counts()\n",
    "y_test_pred_series = pd.Series(y_test_pred)\n",
    "\n",
    "print(\"\\nðŸ”¢ Prediction Counts:\")\n",
    "print(y_test_pred_series.value_counts())\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Evaluation\n",
    "# ---------------------------\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc  = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "test_auc  = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"ðŸ“Œ XGBoost Results\")\n",
    "print(\"----------------------------\")\n",
    "print(f\"Train Accuracy : {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy  : {test_acc:.4f}\")\n",
    "print(f\"Train ROC-AUC  : {train_auc:.4f}\")\n",
    "print(f\"Test ROC-AUC   : {test_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd21e0",
   "metadata": {},
   "source": [
    "## **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe559686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ðŸ“Œ MODEL EVALUATION RESULTS\n",
      "==============================\n",
      "\n",
      "ðŸ”¹ TRAIN PERFORMANCE\n",
      "Accuracy      : 0.6013\n",
      "ROC-AUC       : 0.6110\n",
      "\n",
      "  â€¢ Class 0 Metrics\n",
      "Precision (0) : 0.9556\n",
      "Recall (0)    : 0.6046\n",
      "F1 Score (0)  : 0.7406\n",
      "\n",
      "  â€¢ Class 1 Metrics\n",
      "Precision (1) : 0.0794\n",
      "Recall (1)    : 0.5484\n",
      "F1 Score (1)  : 0.1386\n",
      "\n",
      "ðŸ”¹ TEST PERFORMANCE\n",
      "Accuracy      : 0.5767\n",
      "ROC-AUC       : 0.6115\n",
      "\n",
      "  â€¢ Class 0 Metrics\n",
      "Precision (0) : 0.9478\n",
      "Recall (0)    : 0.5824\n",
      "F1 Score (0)  : 0.7215\n",
      "\n",
      "  â€¢ Class 1 Metrics\n",
      "Precision (1) : 0.0676\n",
      "Recall (1)    : 0.4857\n",
      "F1 Score (1)  : 0.1187\n",
      "\n",
      "ðŸ”¹ CONFUSION MATRIX (Test Set)\n",
      "[[654 469]\n",
      " [ 36  34]]\n",
      "\n",
      "ðŸ”¹ CLASSIFICATION REPORT (Test Set)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.58      0.72      1123\n",
      "           1       0.07      0.49      0.12        70\n",
      "\n",
      "    accuracy                           0.58      1193\n",
      "   macro avg       0.51      0.53      0.42      1193\n",
      "weighted avg       0.90      0.58      0.69      1193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Prepare data\n",
    "# ---------------------------\n",
    "df = pd.read_csv('train.csv')\n",
    "df = df.copy()\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Ensure categorical dtype for object columns (optional)\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].astype('category')\n",
    "X = X[numeric_cols]\n",
    "# Train-test split (stratify to preserve target ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "smote = SMOTE( random_state=42)\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Preprocessing + Logistic Regression Pipeline\n",
    "# ---------------------------\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='saga', n_jobs=-1, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Predictions\n",
    "# ---------------------------\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_train_proba = clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Evaluation\n",
    "# ---------------------------\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"ðŸ“Œ MODEL EVALUATION RESULTS\")\n",
    "print(\"==============================\")\n",
    "\n",
    "# ----- Train Metrics -----\n",
    "print(\"\\nðŸ”¹ TRAIN PERFORMANCE\")\n",
    "print(f\"Accuracy      : {train_acc:.4f}\")\n",
    "print(f\"ROC-AUC       : {train_auc:.4f}\")\n",
    "\n",
    "print(\"\\n  â€¢ Class 0 Metrics\")\n",
    "print(f\"Precision (0) : {precision_score(y_train, y_train_pred, pos_label=0):.4f}\")\n",
    "print(f\"Recall (0)    : {recall_score(y_train, y_train_pred, pos_label=0):.4f}\")\n",
    "print(f\"F1 Score (0)  : {f1_score(y_train, y_train_pred, pos_label=0):.4f}\")\n",
    "\n",
    "print(\"\\n  â€¢ Class 1 Metrics\")\n",
    "print(f\"Precision (1) : {precision_score(y_train, y_train_pred, pos_label=1):.4f}\")\n",
    "print(f\"Recall (1)    : {recall_score(y_train, y_train_pred, pos_label=1):.4f}\")\n",
    "print(f\"F1 Score (1)  : {f1_score(y_train, y_train_pred, pos_label=1):.4f}\")\n",
    "\n",
    "# ----- Test Metrics -----\n",
    "print(\"\\nðŸ”¹ TEST PERFORMANCE\")\n",
    "print(f\"Accuracy      : {test_acc:.4f}\")\n",
    "print(f\"ROC-AUC       : {test_auc:.4f}\")\n",
    "\n",
    "print(\"\\n  â€¢ Class 0 Metrics\")\n",
    "print(f\"Precision (0) : {precision_score(y_test, y_test_pred, pos_label=0):.4f}\")\n",
    "print(f\"Recall (0)    : {recall_score(y_test, y_test_pred, pos_label=0):.4f}\")\n",
    "print(f\"F1 Score (0)  : {f1_score(y_test, y_test_pred, pos_label=0):.4f}\")\n",
    "\n",
    "print(\"\\n  â€¢ Class 1 Metrics\")\n",
    "print(f\"Precision (1) : {precision_score(y_test, y_test_pred, pos_label=1):.4f}\")\n",
    "print(f\"Recall (1)    : {recall_score(y_test, y_test_pred, pos_label=1):.4f}\")\n",
    "print(f\"F1 Score (1)  : {f1_score(y_test, y_test_pred, pos_label=1):.4f}\")\n",
    "\n",
    "# ----- Confusion Matrix -----\n",
    "print(\"\\nðŸ”¹ CONFUSION MATRIX (Test Set)\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm)\n",
    "\n",
    "# ----- Classification Report -----\n",
    "print(\"\\nðŸ”¹ CLASSIFICATION REPORT (Test Set)\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c1e07119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ðŸ“Œ MODEL EVALUATION RESULTS\n",
      "==============================\n",
      "\n",
      "ðŸ”¹ TRAIN PERFORMANCE\n",
      "Accuracy      : 0.8612\n",
      "ROC-AUC       : 0.6902\n",
      "\n",
      "  â€¢ Class 0 Metrics\n",
      "Precision (0) : 0.9516\n",
      "Recall (0)    : 0.8982\n",
      "F1 Score (0)  : 0.9241\n",
      "\n",
      "  â€¢ Class 1 Metrics\n",
      "Precision (1) : 0.1394\n",
      "Recall (1)    : 0.2652\n",
      "F1 Score (1)  : 0.1827\n",
      "\n",
      "ðŸ”¹ TEST PERFORMANCE\n",
      "Accuracy      : 0.8466\n",
      "ROC-AUC       : 0.6273\n",
      "\n",
      "  â€¢ Class 0 Metrics\n",
      "Precision (0) : 0.9493\n",
      "Recall (0)    : 0.8842\n",
      "F1 Score (0)  : 0.9156\n",
      "\n",
      "  â€¢ Class 1 Metrics\n",
      "Precision (1) : 0.1156\n",
      "Recall (1)    : 0.2429\n",
      "F1 Score (1)  : 0.1567\n",
      "\n",
      "ðŸ”¹ CONFUSION MATRIX (Test Set)\n",
      "[[993 130]\n",
      " [ 53  17]]\n",
      "\n",
      "ðŸ”¹ CLASSIFICATION REPORT (Test Set)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92      1123\n",
      "           1       0.12      0.24      0.16        70\n",
      "\n",
      "    accuracy                           0.85      1193\n",
      "   macro avg       0.53      0.56      0.54      1193\n",
      "weighted avg       0.90      0.85      0.87      1193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Prepare data\n",
    "# ---------------------------\n",
    "df = pd.read_csv('train.csv')\n",
    "df = df.copy()\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(columns=['TARGET'])\n",
    "y = df['TARGET']\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Ensure categorical dtype for object columns (optional)\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "# Train-test split (stratify to preserve target ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "smote = SMOTENC(categorical_features=categorical_cols, random_state=42)\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Preprocessing + Logistic Regression Pipeline\n",
    "# ---------------------------\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ],\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='saga', n_jobs=-1, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Predictions\n",
    "# ---------------------------\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_train_proba = clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Evaluation\n",
    "# ---------------------------\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"ðŸ“Œ MODEL EVALUATION RESULTS\")\n",
    "print(\"==============================\")\n",
    "\n",
    "# ----- Train Metrics -----\n",
    "print(\"\\nðŸ”¹ TRAIN PERFORMANCE\")\n",
    "print(f\"Accuracy      : {train_acc:.4f}\")\n",
    "print(f\"ROC-AUC       : {train_auc:.4f}\")\n",
    "\n",
    "print(\"\\n  â€¢ Class 0 Metrics\")\n",
    "print(f\"Precision (0) : {precision_score(y_train, y_train_pred, pos_label=0):.4f}\")\n",
    "print(f\"Recall (0)    : {recall_score(y_train, y_train_pred, pos_label=0):.4f}\")\n",
    "print(f\"F1 Score (0)  : {f1_score(y_train, y_train_pred, pos_label=0):.4f}\")\n",
    "\n",
    "print(\"\\n  â€¢ Class 1 Metrics\")\n",
    "print(f\"Precision (1) : {precision_score(y_train, y_train_pred, pos_label=1):.4f}\")\n",
    "print(f\"Recall (1)    : {recall_score(y_train, y_train_pred, pos_label=1):.4f}\")\n",
    "print(f\"F1 Score (1)  : {f1_score(y_train, y_train_pred, pos_label=1):.4f}\")\n",
    "\n",
    "# ----- Test Metrics -----\n",
    "print(\"\\nðŸ”¹ TEST PERFORMANCE\")\n",
    "print(f\"Accuracy      : {test_acc:.4f}\")\n",
    "print(f\"ROC-AUC       : {test_auc:.4f}\")\n",
    "\n",
    "print(\"\\n  â€¢ Class 0 Metrics\")\n",
    "print(f\"Precision (0) : {precision_score(y_test, y_test_pred, pos_label=0):.4f}\")\n",
    "print(f\"Recall (0)    : {recall_score(y_test, y_test_pred, pos_label=0):.4f}\")\n",
    "print(f\"F1 Score (0)  : {f1_score(y_test, y_test_pred, pos_label=0):.4f}\")\n",
    "\n",
    "print(\"\\n  â€¢ Class 1 Metrics\")\n",
    "print(f\"Precision (1) : {precision_score(y_test, y_test_pred, pos_label=1):.4f}\")\n",
    "print(f\"Recall (1)    : {recall_score(y_test, y_test_pred, pos_label=1):.4f}\")\n",
    "print(f\"F1 Score (1)  : {f1_score(y_test, y_test_pred, pos_label=1):.4f}\")\n",
    "\n",
    "# ----- Confusion Matrix -----\n",
    "print(\"\\nðŸ”¹ CONFUSION MATRIX (Test Set)\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm)\n",
    "\n",
    "# ----- Classification Report -----\n",
    "print(\"\\nðŸ”¹ CLASSIFICATION REPORT (Test Set)\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6adbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
